{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dennis\\AppData\\Local\\Temp\\ipykernel_9372\\3891685128.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_data = filtered_data.groupby('Genmodel_ID').apply(sample_images).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data preprocessing done\n",
      "dataset preparation done\n",
      "model construction done\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 3s 483ms/step - loss: 9.4744 - maker_output_loss: 0.0000e+00 - year_output_loss: 9.4744 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.1375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 11.5855 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 11.5855 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 8.4900 - maker_output_loss: 0.0000e+00 - year_output_loss: 8.4900 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.1875 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 10.2475 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 10.2475 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.2000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 7.4326 - maker_output_loss: 0.0000e+00 - year_output_loss: 7.4326 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.2375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 8.1574 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 8.1574 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.3000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 6.0434 - maker_output_loss: 0.0000e+00 - year_output_loss: 6.0434 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.3375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 4.2740 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 4.2740 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 3.9936 - maker_output_loss: 0.0000e+00 - year_output_loss: 3.9936 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.2375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.6459 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.6459 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 1.9326 - maker_output_loss: 0.0000e+00 - year_output_loss: 1.9326 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.5000 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 6.1931 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 6.1931 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.7257 - maker_output_loss: 0.0000e+00 - year_output_loss: 2.7257 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.3625 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 5.1083 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 5.1083 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.2000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 2.1129 - maker_output_loss: 0.0000e+00 - year_output_loss: 2.1129 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.4375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 3.6518 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 3.6518 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0000e+00 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.3565 - maker_output_loss: 0.0000e+00 - year_output_loss: 1.3565 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.5875 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.3928 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.3928 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.3000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 1.5126 - maker_output_loss: 0.0000e+00 - year_output_loss: 1.5126 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.6125 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 3.0217 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 3.0217 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1.2120 - maker_output_loss: 0.0000e+00 - year_output_loss: 1.2120 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.6875 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.8420 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.8420 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.9180 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.9180 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.6500 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.5644 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.5644 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.6584 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.6584 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.7750 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.2931 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.2931 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.7585 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.7585 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.7375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.6419 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.6419 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.2000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.5163 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.5163 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.8500 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.8354 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.8354 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.5304 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.5304 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.8250 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.1950 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.1950 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.3500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.5155 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.5155 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.8750 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.3937 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.3937 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.0500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.5150 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.5150 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.8375 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.8538 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.8538 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.1500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.3904 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.3904 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.9000 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.9629 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.9629 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.2500 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.4370 - maker_output_loss: 0.0000e+00 - year_output_loss: 0.4370 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.9125 - genmodel_output_accuracy: 0.0000e+00 - val_loss: 2.2779 - val_maker_output_loss: 0.0000e+00 - val_year_output_loss: 2.2779 - val_genmodel_output_loss: 0.0000e+00 - val_maker_output_accuracy: 0.0000e+00 - val_year_output_accuracy: 0.3000 - val_genmodel_output_accuracy: 0.0000e+00\n",
      "model training done\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 2.2779 - maker_output_loss: 0.0000e+00 - year_output_loss: 2.2779 - genmodel_output_loss: 0.0000e+00 - maker_output_accuracy: 0.0000e+00 - year_output_accuracy: 0.3000 - genmodel_output_accuracy: 0.0000e+00\n",
      "[2.2779171466827393, 0.0, 2.2779171466827393, 0.0, 0.0, 0.30000001192092896, 0.0]\n",
      "['loss', 'maker_output_loss', 'year_output_loss', 'genmodel_output_loss', 'maker_output_accuracy', 'year_output_accuracy', 'genmodel_output_accuracy']\n",
      "Maker classification accuracy: 0.00\n",
      "Year classification accuracy: 0.30\n",
      "Genmodel_ID classification accuracy: 0.00\n",
      "1/1 [==============================] - 0s 497ms/step\n",
      "Maker classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Year classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         4\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.56      0.83      0.67         6\n",
      "           6       0.50      0.25      0.33         4\n",
      "\n",
      "    accuracy                           0.30        20\n",
      "   macro avg       0.15      0.15      0.14        20\n",
      "weighted avg       0.27      0.30      0.27        20\n",
      "\n",
      "Genmodel_ID classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dennis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Dennis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Dennis\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "\n",
    "# Define image directory and load CSV\n",
    "image_directory = 'D:\\\\CPEN355_project\\\\Data\\\\DVM_noNest_test'\n",
    "data = pd.read_csv('D:\\\\CPEN355_project\\\\Data\\\\Image_table.csv')\n",
    "\n",
    "# Parse Image_name to extract Maker, Year, Genmodel_ID\n",
    "def parse_image_name(image_name):\n",
    "    parts = image_name.split('$$')\n",
    "    maker = parts[0]\n",
    "    year = parts[2]\n",
    "    genmodel_id = parts[4]\n",
    "    return maker, year, genmodel_id\n",
    "\n",
    "data[['Maker', 'Year', 'Genmodel_ID']] = data['Image_name'].apply(\n",
    "    lambda x: pd.Series(parse_image_name(x)))\n",
    "\n",
    "# Count Genmodel_ID occurrences and filter\n",
    "genmodel_counts = data['Genmodel_ID'].value_counts()\n",
    "valid_genmodels = genmodel_counts[genmodel_counts > 300].index.tolist()\n",
    "filtered_data = data[data['Genmodel_ID'].isin(valid_genmodels)]\n",
    "\n",
    "# Randomly sample 200 images per Genmodel_ID\n",
    "def sample_images(df):\n",
    "    return df.sample(n=100, random_state=42)\n",
    "\n",
    "filtered_data = filtered_data.groupby('Genmodel_ID').apply(sample_images).reset_index(drop=True)\n",
    "\n",
    "# Add full image paths\n",
    "filtered_data['Image_path'] = filtered_data['Image_name'].apply(\n",
    "    lambda x: f\"{image_directory}\\\\{x}\")\n",
    "\n",
    "# Filter non-existent images\n",
    "def image_exists(path):\n",
    "    return Path(path).is_file()\n",
    "\n",
    "exists_mask = filtered_data['Image_path'].apply(image_exists)\n",
    "filtered_data = filtered_data[exists_mask].reset_index(drop=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoders = {}\n",
    "for label, name in zip(['Maker', 'Year', 'Genmodel_ID'], ['Maker', 'Year', 'Genmodel_ID']):\n",
    "    le = LabelEncoder()\n",
    "    label_encoders[name] = le\n",
    "    filtered_data[name + '_enc'] = le.fit_transform(filtered_data[name])\n",
    "\n",
    "# Prepare data\n",
    "image_paths = filtered_data['Image_path']\n",
    "maker_labels = filtered_data['Maker_enc'].values\n",
    "year_labels = filtered_data['Year_enc'].values\n",
    "genmodel_labels = filtered_data['Genmodel_ID_enc'].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train_paths, X_val_paths, y_train_maker, y_val_maker, y_train_year, y_val_year, y_train_genmodel, y_val_genmodel = train_test_split(\n",
    "    image_paths, maker_labels, year_labels, genmodel_labels, test_size=0.2, random_state=42, stratify=genmodel_labels)\n",
    "\n",
    "print(f\"data preprocessing done\")\n",
    "\n",
    "# 2. Dataset Preparation\n",
    "\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path, maker_label, year_label, genmodel_label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_size, img_size])\n",
    "    image = image / 255.0\n",
    "    return image, {\n",
    "        'maker_output': maker_label,\n",
    "        'year_output': year_label,\n",
    "        'genmodel_output': genmodel_label\n",
    "    }\n",
    "# Create datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_paths.values, y_train_maker, y_train_year, y_train_genmodel))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_paths.values, y_val_maker, y_val_year, y_val_genmodel))\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"dataset preparation done\")\n",
    "\n",
    "# 3. Model Construction\n",
    "\n",
    "# Use pretrained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(img_size, img_size, 3)))\n",
    "x = Flatten()(base_model.output)\n",
    "1\n",
    "# Add classification heads\n",
    "maker_output = Dense(len(label_encoders['Maker'].classes_), activation='softmax', name='maker_output')(x)\n",
    "year_output = Dense(len(label_encoders['Year'].classes_), activation='softmax', name='year_output')(x)\n",
    "genmodel_output = Dense(len(label_encoders['Genmodel_ID'].classes_), activation='softmax', name='genmodel_output')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[maker_output, year_output, genmodel_output])\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'maker_output': 'sparse_categorical_crossentropy',\n",
    "                    'year_output': 'sparse_categorical_crossentropy',\n",
    "                    'genmodel_output': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'maker_output': 'accuracy',\n",
    "                       'year_output': 'accuracy',\n",
    "                       'genmodel_output': 'accuracy'})\n",
    "\n",
    "print(f\"model construction done\")\n",
    "\n",
    "# 4. Model Training\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "print(f\"model training done\")\n",
    "\n",
    "# 5. Model Evaluation\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "eval_results = model.evaluate(val_dataset)\n",
    "print(eval_results)\n",
    "print(model.metrics_names)\n",
    "\n",
    "# Correctly map the evaluation results\n",
    "metrics_dict = dict(zip(model.metrics_names, eval_results))\n",
    "\n",
    "print(f\"Maker classification accuracy: {metrics_dict['maker_output_accuracy']:.2f}\")\n",
    "print(f\"Year classification accuracy: {metrics_dict['year_output_accuracy']:.2f}\")\n",
    "print(f\"Genmodel_ID classification accuracy: {metrics_dict['genmodel_output_accuracy']:.2f}\")\n",
    "print(f\"Engine type classification accuracy: {metrics_dict['engine_type_accuracy']:.2f}\")\n",
    "\n",
    "\n",
    "# 6. Compute Precision, Recall, and F1-score\n",
    "\n",
    "# Initialize lists to collect true labels and predictions\n",
    "y_true_maker = []\n",
    "y_true_year = []\n",
    "y_true_genmodel = []\n",
    "y_pred_maker = []\n",
    "y_pred_year = []\n",
    "y_pred_genmodel = []\n",
    "\n",
    "for images, labels in val_dataset:\n",
    "    maker_labels = labels['maker_output']\n",
    "    year_labels = labels['year_output']\n",
    "    genmodel_labels = labels['genmodel_output']\n",
    "    preds = model.predict(images)\n",
    "    pred_maker, pred_year, pred_genmodel = preds\n",
    "\n",
    "    # Since labels are integers, no need to use np.argmax\n",
    "    y_true_maker.extend(maker_labels.numpy())\n",
    "    y_true_year.extend(year_labels.numpy())\n",
    "    y_true_genmodel.extend(genmodel_labels.numpy())\n",
    "\n",
    "    # Predictions are still probabilities, so use np.argmax\n",
    "    y_pred_maker.extend(np.argmax(pred_maker, axis=1))\n",
    "    y_pred_year.extend(np.argmax(pred_year, axis=1))\n",
    "    y_pred_genmodel.extend(np.argmax(pred_genmodel, axis=1))\n",
    "\n",
    "# Compute classification reports\n",
    "print(\"Maker classification report:\")\n",
    "print(classification_report(y_true_maker, y_pred_maker))\n",
    "\n",
    "print(\"Year classification report:\")\n",
    "print(classification_report(y_true_year, y_pred_year))\n",
    "\n",
    "print(\"Genmodel_ID classification report:\")\n",
    "print(classification_report(y_true_genmodel, y_pred_genmodel))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
