{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-23T08:50:16.515110Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
    "                                     Dropout, BatchNormalization, InputLayer)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# path to Image_table.csv\n",
    "image_table = pd.read_csv('D:\\\\CPEN355_project\\\\Data\\\\Image_table.csv')  # Update with actual path\n",
    "# path to Price_table.csv\n",
    "price_table = pd.read_csv('D:\\\\CPEN355_project\\\\Data\\\\Price_table.csv')  # Update with actual path\n",
    "\n",
    "# Merge the tables on 'Genmodel_ID' and keep relevant columns\n",
    "# image_table contains image name, while price table contains price, and they share a column called 'Genmodel_ID'\n",
    "# so we need to merge them\n",
    "merged_data = pd.merge(image_table[['Genmodel_ID', 'Image_name']],\n",
    "                       price_table[['Genmodel_ID', 'Entry_price']],\n",
    "                       on='Genmodel_ID')\n",
    "\n",
    "print(\"data merged\\n\")\n",
    "\n",
    "# Count the number of images per Genmodel_ID\n",
    "image_counts = merged_data['Genmodel_ID'].value_counts()\n",
    "\n",
    "# Remove Genmodel_IDs with fewer than 1000 images\n",
    "valid_genmodels = image_counts[image_counts >= 1000].index\n",
    "\n",
    "# Filter merged_data to only include valid Genmodel_IDs\n",
    "filtered_data = merged_data[merged_data['Genmodel_ID'].isin(valid_genmodels)]\n",
    "\n",
    "# For Genmodel_IDs with counts > 3000, randomly select 3000 images\n",
    "def sample_images(group):\n",
    "    if len(group) > 3000:\n",
    "        return group.sample(n=3000, random_state=42)\n",
    "    else:\n",
    "        return group\n",
    "\n",
    "filtered_data = filtered_data.groupby('Genmodel_ID').apply(sample_images).reset_index(drop=True)\n",
    "\n",
    "print(\"Data filtered\\n\")\n",
    "\n",
    "# path to the training images\n",
    "image_paths = filtered_data['Image_name'].apply(lambda x: f\"D:\\\\CPEN355_project\\\\355DataSet\\\\DVM_noNest\\\\{x}\") # Update with the directory path where images are stored\n",
    "prices = filtered_data['Entry_price'].values\n",
    "\n",
    "# Prepare image data and prices\n",
    "img_size = 224  # Resize images to 224*224\n",
    "batch_size = 32\n",
    "\n",
    "scaler = StandardScaler()\n",
    "prices_scaled = scaler.fit_transform(prices.reshape(-1, 1))\n",
    "\n",
    "X_train_paths, X_test_paths, y_train_scaled, y_test_scaled = train_test_split(\n",
    "    image_paths, prices_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"data splited\\n\")\n",
    "\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_size, img_size])\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_paths.values, y_train_scaled))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_paths.values, y_test_scaled))\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    return data_augmentation(image), label\n",
    "\n",
    "train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(img_size, img_size, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(\"model compiled\\n\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_cnn_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = model.fit(train_dataset, epochs=50,\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "print(\"finished training\\n\")\n",
    "\n",
    "loss, mae = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"standarlized MAE: {mae}\")\n",
    "\n",
    "predictions_scaled = model.predict(test_dataset)\n",
    "predictions_scaled = np.concatenate(predictions_scaled, axis=0)\n",
    "y_test_scaled_flat = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions_scaled.reshape(-1, 1))\n",
    "y_test = scaler.inverse_transform(y_test_scaled_flat.reshape(-1, 1))\n",
    "\n",
    "mae_original = mean_absolute_error(y_test, predictions)\n",
    "print(f\"original MAE: {mae_original}\")\n",
    "print(\"testsample number:\", len(y_test))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "for image, label in test_dataset.unbatch().take(5):\n",
    "    test_images.append(image.numpy())\n",
    "    test_labels.append(label.numpy())\n",
    "\n",
    "test_predictions = model.predict(np.array(test_images))\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "    actual_price = scaler.inverse_transform(test_labels[i].reshape(-1, 1))[0][0]\n",
    "    predicted_price = test_predictions[i][0]\n",
    "    plt.title(f\"perdicted price: {predicted_price:.2f}, actual price: {actual_price:.2f}\")\n",
    "\n",
    "    plt.show() "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data merged\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dennis\\AppData\\Local\\Temp\\ipykernel_12212\\3860512162.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_data = filtered_data.groupby('Genmodel_ID').apply(sample_images).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data filtered\n",
      "\n",
      "data splited\n",
      "\n",
      "model compiled\n",
      "\n",
      "Epoch 1/50\n",
      "29216/29216 [==============================] - 2174s 74ms/step - loss: 0.7391 - mae: 0.4481 - val_loss: 0.6073 - val_mae: 0.3662\n",
      "Epoch 2/50\n",
      "29216/29216 [==============================] - 2203s 75ms/step - loss: 0.5332 - mae: 0.3895 - val_loss: 0.4069 - val_mae: 0.3371\n",
      "Epoch 3/50\n",
      "29216/29216 [==============================] - 2333s 80ms/step - loss: 0.4650 - mae: 0.3696 - val_loss: 0.4076 - val_mae: 0.3369\n",
      "Epoch 4/50\n",
      "29216/29216 [==============================] - 2723s 93ms/step - loss: 0.4231 - mae: 0.3551 - val_loss: 0.4025 - val_mae: 0.3600\n",
      "Epoch 5/50\n",
      "29216/29216 [==============================] - 3199s 109ms/step - loss: 0.3922 - mae: 0.3440 - val_loss: 0.4955 - val_mae: 0.3445\n",
      "Epoch 6/50\n",
      "26234/29216 [=========================>....] - ETA: 5:41 - loss: 0.3698 - mae: 0.3357"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
